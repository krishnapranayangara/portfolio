<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Emotion Classifier | Krishna Pranay Angara</title>
<meta name="keywords" content="">
<meta name="description" content="Summary The project discussed is based on the Image classification problem using deep convolution neural networks. The convolution networks use multiple hidden layers by taking in the data extracted using beautiful soup framework to classify the emotions of the human object present in the images. The multiclass model generated learns through the data of images to recognize the emotions. The images are classified into happy and sad while feeding the model.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/emotionrecognizer/second/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.54405a410796490bc874ab6181fac9b675753cc2b91375d8f882566459eca428.css" integrity="sha256-VEBaQQeWSQvIdKthgfrJtnV1PMK5E3XY&#43;IJWZFnspCg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/emotionrecognizer/second/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Krishna Pranay Angara (Alt + H)">Krishna Pranay Angara</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/journey/" title="Journey">
                    <span>Journey</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/contact/" title="Contact">
                    <span>Contact</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Emotion Classifier
    </h1>
    <div class="post-meta"><span title='2024-08-06 15:16:34 -0200 -0200'>August 6, 2024</span>&nbsp;·&nbsp;11 min

</div>
  </header> 
  <div class="post-content"><h1 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h1>
<p>The project discussed is based on the Image classification problem using deep convolution
neural networks. The convolution networks use multiple hidden layers by taking in the data
extracted using beautiful soup framework to classify the emotions of the human object present in
the images. The multiclass model generated learns through the data of images to recognize the
emotions. The images are classified into happy and sad while feeding the model. Multiple
activations are applied to understand the tendencies of accuracy, based on activation functions
and the number of layers used in the network. The best model based on the ROC curve is used
for the prediction.</p>
<h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>Computer Vision is a sub-branch of Artificial Intelligence. Computer Vision deals with Image
and object recognition through real time or on existing data sets to understand the object and its
surroundings. In the year 1959, popular work by Hubel and Wiesel [1] discussed how the visual
cortex in cats’ brain handles understanding spatial data field. The visual image is not taken at
once rather, the receptive fields would be covering smaller regions of this spatial data and
multiple receptive fields with overlapping spatial regions fire neurons to the visual cortex.
Together they form the complete spatial data field. Hubel and Wiesel proposed a technique for
using a similar method to identify patterns in a dataset. Followed by this work a basic
convolution neural network has been created in 1980 by Knihiko Fukushima [3]. The convoluted
layers take multiple smaller regions of the earlier layer, and the feature extraction is done
through spatial averaging. The final layer correctly identifies the object. Later in the year 1994,
the first ever Convolution neural network for computing high resolution images has been
successfully implemented by Yann LeCun, Leon Bottou, Yosuha Bengio and Patrick Haffner.
Named after Yann LeCun, the LeNet-5 architecture discusses the convolution layer modules
including the input layer, Sampling layer or feature extraction layer, fully connected layer and
the final output layer [2]. Feature extraction stands out as being a crucial step as these values
would decide the learning points of all the neurons for n hidden layers.
Max Pooling has been a popular feature extraction method. The maximum elements of a region
from previous layers are considered and resized to send through the next layer of neurons. This
preserves the key features and reduces the layer size efficiently. The concept of max pooling was
introduced by Yamaguchi in 1990 [4].</p>
<p><img loading="lazy" src="content/images/image-1.png" alt="Le Net5"  />
</p>
<p>Computer Vision has come a long way from trivial Matrix operations for image manipulations to
using real time video in aiding major health and defense applications. Mathematics at its core,
we will try to understand how we could use convolution neural networks in object detection and
how labeled data could help the model predict emotions of a person. We use supervised learning
for training our model with train data and then evaluate it with random images.
Neural networks, much like our brain, use neurons to learn parts of data from the training set and
give us a prediction based on previously learnt values. Emotions give meaning and purpose to
human life. They are a particularly important phenomenon that affects human ways of life. We
will try to build a model that can predict 2 very important emotions out of many, i.e., happy and
sad. The neurons in our brain communicate via electric signals, The neurons in the neural
network communicate through numbers and mathematical operations.</p>
<p><img loading="lazy" src="C:%5cUsers%5ckrish%5cportfolio%5ccontent%5cimages%5cimage-1.png" alt="NeuralNetwork"  />
</p>
<p>Several proposed frameworks help us in building neural networks seamlessly. The precision and
accuracy of these models could be managed via hyper parameter tuning. Regardless of the model
efficiency, data integrity and correctness are huge factors in Image detection. Normalizing the
data for removing noise and data being independent of geometric distortion is crucial.</p>
<h1 id="method">Method<a hidden class="anchor" aria-hidden="true" href="#method">#</a></h1>
<p>Through web scraping using beautiful soup framework, happy and sad data is collected. The
Source would be taking in the request URL and based on the source link would collect images in
that webpage. We could modify this URL to include webpage 2,3 and 4 to collect data. The
images would then be labeled based on the image download number and stored in the image path
specified by us. A total of 480 images have been considered regardless of the image resolution.
Some of the images with their labels could be shown in figure 3.
Import all the necessary packages and libraries for operating on image data and model
generation. TensorFlow using keras is utilized for neural networks. Various functions such as
sequential, conv2D, MaxPooling2D and Dense layers are imported for tuning the neural
network. A roc curve is imported to estimate the best network for prediction. AUC and precision
enable us to measure the accuracy of models.</p>
<p><img loading="lazy" src="image.png" alt="sample images"  />
</p>
<p>The images would be considered as NumPy matrices. The values would range from 1 to 255.
Working on this data would be computationally intensive. For more efficiency we will normalize
the data and reduce the pixel values. Split the data to train, validation and test values.</p>
<p><img loading="lazy" src="image-1.png" alt="happy and sad images"  />
</p>
<p>Understanding various activation function combinations with varying number of layers is the
primary aim of the paper. There are several nonlinear activation functions that could be applied
on complex convolution networks such as sigmoid, Relu and Tanh. Throughout the discussion
we will be considering the different number of layers and mainly 3 combinations of activation
functions mentioned above.
According to Tomasz Szandala, Relu has much better execution and training time when
compared with other activation Functions. We would analyze if this true using our convolution
neural networks. The tendencies of activation efficiency if calculated based on training 10,000
images of CIFAR10 dataset with different activation functions [5]. The results and findings can
be seen in figure 5.</p>
<p><img loading="lazy" src="image-2.png" alt="Analysis"  />
</p>
<h2 id="model-1">Model 1<a hidden class="anchor" aria-hidden="true" href="#model-1">#</a></h2>
<p>The Model 1 takes in an input size of 256<em>256 with 3 channels. The convolution layers take in
the images and are sent through 16 layers of neurons where the kernel size of 5</em>5 would be
applied to those 16 kernels and the results would be sent to 32 layers of neurons and then again
through 16 layers. The Kernel size and padding are consistent across all the layers. The hidden
layers would be using RElu while the final dense layer uses sigmoid activation function. RElu or
a Rectified Linear Unit function outputs the input if the value is positive else zero
(max{input,0}) as shown in formula 1.
The activation layer acts after the summation step and then defines output accordingly. The
simple form of computation based on the formula below allows the model to run more smoothly
and efficiently.</p>
<p><img loading="lazy" src="image-3.png" alt="formula"  />
</p>
<p>The Rectilinear Activation Function is more commonly used in deep learning models because of
this reason. The sparsity of a model is an important feature i.e., The number of unwanted neurons
in the model needs to be ignored and the number of neurons that could provide necessary
information needs to be considered. The number of unwanted neurons is significantly less in
Relu as it nullifies the 0 values and will only consider the neurons with values greater than 0.
The graph when considering inputs x and outputs f(x) or y can be seen in figure 6.</p>
<p><img loading="lazy" src="image-4.png" alt="relu"  />
</p>
<h2 id="model-2">Model 2<a hidden class="anchor" aria-hidden="true" href="#model-2">#</a></h2>
<p>The emphasis is more on sigmoid activation function instead of Rectified Linear Unit. All the
hidden layers would be using Sigmoid except the final layer which would be using RElu
(Rectified Linear Unit). The sigmoid function has a range of (0,1). This helps us learn
nonlinearly separable values. This synonymous logistic function helps us classify our outputs to
either true or false. The mathematical equation for applying logistic function would be shown in
the figure below.</p>
<p><img loading="lazy" src="image-5.png" alt="sigmoid"  />
</p>
<p>Regardless of the usefulness of sigmoid activation function, when used along with RElu
produced reduced accuracies when compared to model1. The increase in the number of hidden
layers and epochs rendered no major improvement in improved accuracy.</p>
<h2 id="model-3">Model 3<a hidden class="anchor" aria-hidden="true" href="#model-3">#</a></h2>
<p>In model 3 we have considered the use of tanh (tangent hyperbolic function). An important
concept in deep learning is understanding gradients. To extract a good amount of information in
the images we need a good understanding of gradients. Gradients are the building blocks for
image processing. When compared with sigmoid, tanh gives us greater gradients [6]. The
mathematical equation for performing tanh can be seen in the following figure8 [7].</p>
<p><img loading="lazy" src="image-6.png" alt="tanh function"  />
</p>
<p>The higher the gradient information the more learnings would be. Thus, tanh has been considered
instead of sigmoid to understand its influence in improving accuracy. The gradients when plotted
could be as represented in figure 9.</p>
<p><img loading="lazy" src="image-7.png" alt="gradients"  />
</p>
<p>Evidently the results show that using tanh has improved accuracy significantly. However, the
Model 1 using RELU activation provides much better accuracy and reduced loss values when
compared. This is due to the vanishing gradient problem. We will discuss more about this in the
discussion and analysis phase.</p>
<h1 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h1>
<p>The data has been split into train test and validation data points. The data sets thus will be stored
in the image batches (ibatch), to be fed to the model along with their labels. The Image
classification is binary classifier that takes in the Boolean values of 0 and 1. 1 being sad and 0
being happy. Model 1 has comparatively better results where the loss has been gradually
decreasing to 0. The image batches are then fed into the model with the specified hyper
parameters. The summary of operations would be stored in the logs using TensorFlow call backs.
I have run the model for 45 epochs with a default batch size of 32. Learning rate would be 0.01.
Interpolation for the image dataset would be bilinear interpolation. Interpolation helps in scaling
the data for better learning and prediction capabilities. Model1 steadily improves in accuracy for
45 epochs and reaches a stagnation. Model 2 performs well but fails to achieve accuracy greater
than 60%. This is due to the vanishing gradient issue discussed in the analysis section. Model 3
has improved accuracy and performance with a precision of over 70% due to the tanh activation
yet does not exceed model 1 accuracy scores.</p>
<p><img loading="lazy" src="image-10.png" alt="model 1 tendencies"  />

<img loading="lazy" src="image-11.png" alt="model 2 tendencies"  />

<img loading="lazy" src="image-9.png" alt="model 3 tendencies"  />
</p>
<h1 id="discussion-and-analysis">Discussion and analysis<a hidden class="anchor" aria-hidden="true" href="#discussion-and-analysis">#</a></h1>
<p>The deep learning neural networks are improved neural networks with more hidden layers. These
perform exceptionally well with substantial amounts of data. However, the activation functions
such as sigmoid still suffer from a phenomenon known as vanishing gradient problem.
The neural networks will take in the input and pass them to hidden layers and gives out an
output, through this process the forward propagation uses varied weights and biases. The weights
are multiplied with the inputs and the aggregate sum is added to bias which in turn goes through
the activation function to give us the output. Backward propagation is the next step after forward
propagation. A loss function gets calculated using the prediction from the forward propagation
learnings as shown in figure 13. Here the y depicts the prediction and mx+b would be the output
with m being weight and b the bias.</p>
<p><img loading="lazy" src="image-12.png" alt="formula 2"  />
</p>
<p>The weights and biases are updated accordingly for a reduced loss function. At each iteration, the
loss function is calculated using the derivative of earlier input and learning rate. The formula for
calculating the gradient descent can be seen in figure14.</p>
<p><img loading="lazy" src="image-13.png" alt="Loss function"  />
</p>
<p>All the new weights are dependent on the old weights, since the main criterion for gradient
descent is finding the minima and reducing the loss function, the gradient of loss function based
on the derivatives of earlier inputs would be steadily decreasing till it’s close to zero. This
phenomenon is known as vanishing gradient problem. This problem has a significant impact for
deep layers resulting in reduced accuracy. This problem persists for tanh and can be fixed only
through the use Rectified linear unit function. Relu only has the derivative values of 0 and 1 thus
giving us 0 only if the results are less than 0, this helps us prevent vanishing gradient problem.
However, from the figure (15) below we can see that the model 1 which uses relu quickly
overfits the results to 1. This is due to the convergence, the very concept of relu is giving us a 0
or 1 output instead of some fraction between 0 and 1 like sigmoid and tanh. This means that the
model will learn much faster and takes all the positive values and nullifies negative values. Thus,
the model using relu converges much quicky than sigmoid and tanh giving us an accuracy of
100%.</p>
<p><img loading="lazy" src="image-14.png" alt="Comparision"  />
</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>To Summarize, we have extracted datasets from the internet using beautiful soup, a web scraping
tool and used preprocessed the data through normalizing and resizing it to train our three
different models of convolution neural networks. The data has been further split into training,
testing and validation splits and were fed into the models. The model 1 performed much better
than model 2 and 3. The reason for the reduced prediction accuracy of the latter models is due to
the phenomenon known as vanishing gradient descent. We have generated an ROC curve to
visualize the best model.</p>
<p><img loading="lazy" src="image-15.png" alt="AOC curve"  />
</p>
<p>From Figure 16, the best model is Relu model and thus we have used it for the prediction of a
test image. The outputs have proven that the images have been predicted correctly.</p>
<p><img loading="lazy" src="image-16.png" alt="prediction"  />
</p>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<ol>
<li>Hubel, DH; Wiesel, TN (October 1959). &ldquo;Receptive fields of single neurones in the cat&rsquo;s
striate cortex&rdquo;. J. Physiol. 148 (3): 574–91. doi:10.1113/jphysiol. 1959.sp006308. PMC 1363130.
PMID 14403679.</li>
<li>LeCun, Yann; Léon Bottou; Yoshua Bengio; Patrick Haffner (1998). &ldquo;Gradient-based learning
applied to document recognition&rdquo; (PDF). Proceedings of the IEEE. 86 (11): 2278–2324.
CiteSeerX 10.1.1.32.9552. doi:10.1109/5.726791. S2CID 14542261</li>
<li>Fukushima, Kunihiko (1980). &ldquo;Neocognitron: A Self-organizing Neural Network Model for a
Mechanism of Pattern Recognition Unaffected by Shift in Position&rdquo;</li>
<li>Yamaguchi, Kouichi; Sakamoto, Kenji; Akabane, Toshio; Fujimoto, Yoshiji (November
1990). A Neural Network for Speaker-Independent Isolated Word Recognition. First
International Conference on Spoken Language Processing (ICSLP 90). Kobe, Japan.</li>
<li>Tomasz Szandała, Review and Comparison of Commonly Used Activation Functions for Deep
Neural Networks, arXiv:2010.09458 [cs.LG]</li>
<li><a href="https://www.baeldung.com/cs/sigmoid-vs-tanh-functions">https://www.baeldung.com/cs/sigmoid-vs-tanh-functions</a></li>
<li><a href="https://analyticsindiamag.com/most-common-activation-functions-in-neural-networks-and-rationale-behind-it/">https://analyticsindiamag.com/most-common-activation-functions-in-neural-networks-and-rationale-behind-it/</a></li>
<li><a href="https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html">https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html</a></li>
<li><a href="https://github.com/nicknochnack/ImageClassification">https://github.com/nicknochnack/ImageClassification</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Krishna Pranay Angara</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
